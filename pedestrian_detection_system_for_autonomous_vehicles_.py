# # -*- coding: utf-8 -*-
# """pedestrian detection system for autonomous vehicles .ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1VJ7UGsZArb57QLzJ8wF6RywssOVC79jJ

# using the YOLOv5 model. The project involves using a pre-trained YOLOv5 model to detect pedestrians in real-time video feeds. YOLOv5 is a fast and accurate object detection model suitable for this purpose.
# Steps Involved:
# Install dependencies.
# Load the pre-trained YOLOv5 model.
# Capture the video feed from a camera or video file.
# Detect pedestrians using the model.
# Display the detections in real-time.
# Let's walk through the code:

# Step 1: Install Dependencies
# Install necessary libraries like torch, opencv-python, and yolov5
# """

# pip install torch torchvision opencv-python pillow

# """Download the YOLOv5 code from its official GitHub repository if you haven't already:

# """

# # Commented out IPython magic to ensure Python compatibility.
# !git clone https://github.com/ultralytics/yolov5
# # %cd yolov5
# !pip install -r requirements.txt



# """**Step 2**: Pedestrian Detection Code Using YOLOv5

# """

# # Import necessary libraries
# import cv2  # OpenCV for video processing
# import torch  # PyTorch to run YOLOv5 model
# import numpy as np  # To handle array manipulations
# #Import necessary patch for cv2_imshow
# from google.colab.patches import cv2_imshow

# # Load YOLOv5 model (pre-trained on COCO dataset)
# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# # Classes in the COCO dataset, 'person' is at index 0
# # YOLOv5 is trained on 80 classes from COCO
# COCO_CLASSES = model.names  # ['person', 'bicycle', 'car', ...]
# # Initialize video capture from a webcam (use video file by providing the file path instead of 0)
# cap = cv2.VideoCapture('0')

# #This opens the webcam for capturing video.
# #You can replace 0 with a video file path if you want to process a pre-recorded video.

# # Function to process each frame and detect pedestrians
# def detect_pedestrians(frame):
#     """
#     Detect pedestrians in the input video frame.

#     Args:
#         frame (ndarray): Input video frame from the webcam or video.

#     Returns:
#         frame (ndarray): Frame with bounding boxes and labels drawn.
#     """
#     # Resize the frame to 640x640 (size expected by YOLOv5)
#     resized_frame = cv2.resize(frame, (640, 640))

#     # Perform detection using YOLOv5
#     results = model(resized_frame)

#     # Extract the detection results
#     # results.xyxy: coordinates, confidence scores, and class IDs
#     detections = results.xyxy[0].numpy()

#     # Loop through detections and draw bounding boxes for pedestrians
#     for detection in detections:
#         x1, y1, x2, y2, confidence, class_id = detection

#         # YOLOv5 outputs normalized bounding box coordinates, so we round them off to pixel coordinates
#         x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

#         # If the detected class is 'person' (class_id 0)
#         if int(class_id) == 0:
#             #Detecting Pedestrians:

#             #The detect_pedestrians function resizes the frame to 640x640 (required by YOLOv5) and processes it with the model.
#             #It then extracts the bounding boxes, confidence scores, and class IDs for each detected object.
#             # Draw a bounding box around the detected person
#             cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#             #For each detected "person" (class_id == 0), a green rectangle (bounding box) is drawn around the pedestrian in the video feed.


#             # Put a label showing 'Person' and the confidence score
#             label = f"Person: {confidence:.2f}"
#             cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

#     return frame

# # Start processing the video feed
# while cap.isOpened():
#     # Read a frame from the video capture
#     ret, frame = cap.read()

#     # Check if frame is successfully captured
#     if not ret:
#         print("Failed to capture frame. Exiting...")
#         break

#     # Detect pedestrians in the frame
#     output_frame = detect_pedestrians(frame)

#     # Display the output frame with bounding boxes
#     cv2_imshow(output_frame)
#     #This line displays the processed video
#     #frames in a window with bounding boxes around detected pedestrians.
#     #Exiting the Loop:
#     # Press 'q' to exit the video window
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# # Release the video capture object and close all OpenCV windows
# cap.release()
# cv2.destroyAllWindows()

